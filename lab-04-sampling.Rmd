---
title: "Lab 04 — Sampling from Time Series"
author: "EAES 480 — Modern Statistics in Earth & Environmental Science"
date: "`r format(Sys.Date(), '%B %d, %Y')`"
output:
  html_document:
    theme: cosmo
    highlight: tango
    toc: true
    toc_depth: 3
    toc_float: true
    code_folding: hide
    df_print: paged
editor_options:
  chunk_output_type: inline
---

```{r setup, echo=FALSE, message=FALSE, warning=FALSE}
library(tidyverse)
library(lubridate)
library(janitor)

knitr::opts_chunk$set(
  warning = FALSE,
  message = FALSE
)
```

# Overview

## What is AmeriFlux?

**AmeriFlux** is a network of **eddy covariance** flux-tower sites that measure exchanges of **carbon (CO₂), water, and energy** between ecosystems and the atmosphere, with standardized data products shared for research and education.

In this lab, you will use a simplified AmeriFlux-style dataset from the **US-AMS site at Argonne National Laboratory (near Chicago)**. The measurements are at **30-minute resolution** over **2023**, and show strong **seasonality** and **day–night cycles**.

**Key idea for this lab:** treat the full 2023 time series as the **population**, then practice sampling strategies to estimate population parameters.

References for context:
- AmeriFlux overview: https://ameriflux.lbl.gov/about/about-ameriflux/
- US-AMS site page: https://ameriflux.lbl.gov/sites/siteinfo/US-AMS

---

# Learning goals

By the end of this lab, you should be able to:

- Define a **population** and a **sample** for an EAES time-series dataset
- Compute population **parameters** (mean, SD) and compare to sample **estimates**
- Visualize distributions and identify **latent grouping variables** (month, day/night)
- Implement **simple random sampling** and **stratified sampling**
- Use `set.seed()` to make sampling reproducible

---

# Data

## Load and inspect

```{r load_data, echo=TRUE, eval=TRUE}
df <- read_csv("data/us-ams-simple.csv") %>%
  clean_names() %>% filter(year_local == 2023)

glimpse(df)
```

**CHECK:** You should see columns like `year_local`, `doy`, `daytime`, and flux/biomet variables (e.g., `gpp`, `fc`, `le`, `ta`).

---

## Create a date and month column from DOY

This dataset uses **Year + Day-of-Year (DOY)**. Month must be derived from a calendar date.

```{r derive_time, echo=TRUE, eval=TRUE}
df <- df %>%
  filter(year_local == 2023, doy >= 1, doy <= 366)
df <- df %>%
  mutate(
    # TODO: create a Date column from year_local and doy
    # HINT: Jan 1 is DOY = 1, so use (doy - 1) with origin = "YYYY-01-01"
    date = as.Date(doy - 1, origin = paste0(year_local, "-01-01")),

    # TODO: create a month column (numeric 1–12 or labeled months)
    month = month(date, label = TRUE, abbr = TRUE),

    # TODO: make a day/night label using daytime (0/1)
    day_night = if_else(daytime == 1, "Day", "Night")
  )

count(df, month)
count(df, day_night)
```

---

# Choose a response variable

You will analyze **one response variable** throughout the lab. This could be a CO₂ flux metric or a meteorological variable.

Examples you can choose from (depending on what you see in the dataset):
- CO₂ / carbon: `gpp`, `reco`, `fc`
- Energy: `le`
- Meteorology: `ta`, `ts`, `swc`

```{r choose_response, echo=TRUE, eval=TRUE}
# TODO: choose ONE response variable (a column name as a string)
response_var <- "le"   # replace "gpp" with your choice, e.g. "fc" or "le" or "ta"

# CHECK: print a quick summary
df %>% summarise(
  n = n(),
  n_missing = sum(is.na(.data[[response_var]])),
  mean = mean(.data[[response_var]], na.rm = TRUE),
  sd = sd(.data[[response_var]], na.rm = TRUE)
)
```

**Prompt (2–3 sentences):** Why did you choose this response variable? What do you expect its seasonality/day–night pattern to be?

> I choose le (energy) as the response variable because it directly reflects the energy exchange between the surface and the atmosphere. I expect that le will be strong in summer and weak in winter,and it should be higher during the day and lower or close to zero at night.

---

# Section 1 — Data dictionary (conceptual)

Students will populate the data dictionary using:
https://ameriflux.lbl.gov/data/aboutdata/data-variables/

Fill in at least **5 variables** from this dataset:

| Variable | Units | Description | Expected sign/seasonality? |
|----------|-------|-------------|----------------------------|
| le |    W m-2   |   Latent heat turbulent flux (no storage correction)   |  Summer high, winter low. Typically higher during daytime and near zero at night. Strong seasonality   |
|  DO   |  µmol L-1  |  Dissolved oxygen in water   |  Higher in colder seasons                      |
|   PCH4  | nmolCH4 mol-1  | Dissolved methane (CH4) in water   |   Higher in warm seasons          |
|  PCO2 | µmolCO2 mol-1 |  Dissolved carbon dioxide (CO2) in water |  Higher in warm seasons      |
| DBH  |  cm  |  Diameter of tree measured at breast height (1.3m) with continuous dendrometers   |  May have seasonal growth pulses (spring/summer)     |

---

# Section 2 — Visualizing the population

Remember: for this lab, the **population** is the entire 2023 half-hourly time series.

## 2.1 Time series view

```{r plot_time_series, echo=TRUE, eval=TRUE}
# GOAL: Visualize seasonality over the year.
# TODO: pick a y aesthetic using response_var.

df %>%
  ggplot(aes(x = date, y =.data[[response_var]])) +
  geom_line(alpha = 0.25) +
  theme_classic(base_size = 18) +
  labs(
    x = NULL,
    y = response_var,
    title = "Population time series (2023)"
  )
```

**Prompt (2–3 sentences):** What major patterns do you see? (Seasonal cycle? Daily cycle? Outliers?)

> The LE time series shows a clear seasonal pattern across 2023. Values are much higher in the summer and much lower (often near zero) in the winter. There is also noticeable short-term variation throughout the year, which likely reflects day–night changes and weather events.

---

## 2.2 Population distribution (histogram + density)

```{r pop_distribution, echo=TRUE, eval=TRUE}
# GOAL: See the overall distribution of the population.
# TODO: choose an appropriate number of bins (start with ~50).

ggplot(df, aes(x = .data[[response_var]])) +
  geom_histogram(bins = 50, alpha = 0.7) +
  theme_classic(base_size = 18) +
  labs(x = response_var, y = "Count", title = "Population distribution (histogram)")

ggplot(df, aes(x = .data[[response_var]])) +
  geom_density(alpha = 0.7) +
  theme_classic(base_size = 18) +
  labs(x = response_var, y = "Density", title = "Population distribution (density)")
```

**Prompt:** Describe shape (skew, modality), center, and spread.

> LE is very right-skewed, with lots of low values and a long tail of high values. The high LE values probably happen mostly during summer daytime, while winter and nighttime values stay close to zero.

---

## 2.3 Do latent groups explain variability? (month, day/night)

### By month

```{r pop_by_month, echo=TRUE, eval=TRUE}
# TODO: make month appear in a sensible order (it already is an ordered factor if label=TRUE)
df %>%
  ggplot(aes(x = month, y = .data[[response_var]])) +
  geom_boxplot(outlier.alpha = 0.25) +
  theme_classic(base_size = 18) +
  labs(x = NULL, y = response_var, title = "Population by month")
```

### By day/night

```{r pop_by_daynight, echo=TRUE, eval=TRUE}
df %>%
  ggplot(aes(x = day_night, y = .data[[response_var]])) +
  geom_boxplot(outlier.alpha = 0.25) +
  theme_classic(base_size = 18) +
  labs(x = NULL, y = response_var, title = "Population by day vs night")
```

**Prompt (3–4 sentences):** Which grouping variable (month or day/night) seems to explain more variability in your response? Why?

> I think month explains more variability in LE because the values are much higher in summer and much lower in winter. Day vs night is also important since LE is usually higher during the day and close to zero at night. But the seasonal change across months looks bigger overall.
---

# Section 3 — Population parameters (truth)

Compute the population mean and SD for your chosen response variable.

```{r population_params, echo=TRUE, eval=TRUE}
pop_mean <- mean(df[[response_var]], na.rm = TRUE)
pop_sd   <- sd(df[[response_var]], na.rm = TRUE)

tibble(
  response_var = response_var,
  population_mean = pop_mean,
  population_sd = pop_sd
)
```

---

# Section 4 — Simple random sampling (SRS)

## 4.1 One random sample

```{r one_sample, echo=TRUE, eval=TRUE}
set.seed(480)

# TODO: choose a sample size (e.g., 200, 500, 1000)
n_samp <- 200

samp <- df %>%
  slice_sample(n = n_samp)

samp_mean <- mean(samp[[response_var]], na.rm = TRUE)
samp_sd   <- sd(samp[[response_var]], na.rm = TRUE)

tibble(
  n_samp = n_samp,
  sample_mean = samp_mean,
  sample_sd = samp_sd,
  pop_mean = pop_mean,
  pop_sd = pop_sd
)
```

**Prompt (2–3 sentences):** How close is your one-sample estimate to the population mean/SD? Is the difference surprising?

> The one-sample estimate was pretty close to the population values. The sample mean (63.01) is only slightly higher than the population mean (61.37), and the SD is also very similar. Any small differences are expected since this is just one random sample of 200 points.

---

## 4.2 Sampling variability: many samples → many means

```{r sampling_distribution, echo=TRUE, eval=TRUE}
set.seed(480)

reps <- 500   # TODO: choose number of replicates (e.g., 500 or 1000)

means <- replicate(
  reps,
  df %>%
    slice_sample(n = n_samp) %>%
    summarise(m = mean(.data[[response_var]], na.rm = TRUE)) %>%
    pull(m)
)

ggplot(tibble(mean_est = means), aes(mean_est)) +
  geom_histogram(bins = 40, alpha = 0.8) +
  geom_vline(xintercept = pop_mean, linetype = "dashed", linewidth = 1.1) +
  theme_classic(base_size = 18) +
  labs(
    x = paste0("Sample mean of ", response_var),
    y = "Count",
    title = "Sampling distribution of the mean (SRS)",
    subtitle = "Dashed line = population mean"
  )
```

**Prompt (2–3 sentences):** Is the sampling distribution centered on the population mean? What happens if you increase `n_samp`?

> Yes, the sampling distribution is centered close to the population mean (dashed line). This suggests that the sample mean is a good estimator of the population mean. If I increase n_samp, the sampling distribution should become narrower, meaning the sample means would vary less from sample to sample.

---

# Section 5 — Stratified sampling

Here you’ll test whether stratification helps when the population has structure.

## 5.1 Stratify by month

```{r strat_by_month, echo=TRUE, eval=TRUE}
set.seed(480)

# GOAL: sample within each month to ensure seasonal representation.
# TODO: choose n_per_month so total sample size is reasonable (e.g., 12 * 20 = 240)
n_per_month <- 20

samp_strat <- df %>%
  group_by(month) %>%
  slice_sample(n = n_per_month) %>%
  ungroup()

strat_mean <- mean(samp_strat[[response_var]], na.rm = TRUE)
strat_sd   <- sd(samp_strat[[response_var]], na.rm = TRUE)

tibble(
  n_per_month = n_per_month,
  total_n = nrow(samp_strat),
  strat_mean = strat_mean,
  strat_sd = strat_sd,
  pop_mean = pop_mean,
  pop_sd = pop_sd
)
```

---

## 5.2 Compare strategies (SRS vs stratified)

```{r compare_sampling, echo=TRUE, eval=TRUE}
tibble(
  strategy = c("Population", "SRS", "Stratified by month"),
  mean = c(pop_mean, samp_mean, strat_mean),
  sd   = c(pop_sd,   samp_sd,   strat_sd)
)
```

**Prompt (3–4 sentences):** Which strategy better approximated the population mean and SD for your response variable? Why might stratification help (or not) here?

> In this run, SRS was closer to the population mean and SD. The stratified sample mean was higher, probably because it ensured equal representation of summer months when LE is higher. Stratification sampling can help avoid missing parts of the seasonal cycle, but it cannot guarantee a better estimate every time.

---

# Section 6 — Conceptual reflection

Answer in **4–6 sentences**:

- Why does seasonality matter for sampling?
- What happens if sampling ignores latent grouping variables?
- In EAES field studies, when is stratification essential?
- What is one trade-off of stratified sampling?

> Seasonality matters for sampling because variables like LE change a lot across the year, and summer values are much higher than winter values. 
If sampling ignores latent grouping variables (like month or day/night), a random sample could accidentally include too many winter or nighttime points, which would bias the estimate of the population mean. 
In EAES field studies, stratification is essential when the population has strong structure, such as seasonal cycles, elevation zones, land cover types, or different hydrologic conditions. Stratified sampling helps ensure all important conditions are represented.
One trade-off is that stratified sampling can be more complicated to design and may require more planning and effort than simple random sampling.

---

# Part II — Sampling designs extensions (graded practice)

In Part I you treated the full 2023 half-hourly record as a **population**, then compared **simple random sampling** (SRS) vs **stratified sampling by month**.

Now you will practice additional **sampling designs** discussed in lecture:

- **Systematic** sampling (regular interval)
- **Cluster** sampling (sample groups, then measure everything in them)
- **Quasi-continuous** sampling (regular time series subsampling)
- **Blocked** designs (preview only — think “blocks as structure”)

All exercises below should run using the same objects from Part I:
- `df` (with `date`, `month`, `day_night`)
- `response_var`
- `pop_mean`, `pop_sd`
- your SRS sample `samp` and stratified sample `samp_strat` (if you created them)

> **Tip:** If you renamed objects in Part I, update the code below to match your names.

---

## Exercise 1 — Systematic sampling (every k-th observation)

**Idea:** sample at a fixed interval (e.g., every 48th record ≈ daily at 30-min resolution).

**Risk:** if the variable has strong cycles aligned with the interval, systematic sampling can be biased.

```{r systematic_sampling, echo=TRUE, eval=FALSE}
# GOAL: Create a systematic sample and compare mean/sd to population.
# TODO: choose an interval k (try 48, 24, 96).
k <- ___

sys_samp <- df %>%
  # TODO: keep only non-missing response values
  filter(!is.na(.data[[response_var]])) %>%
  slice(seq(1, n(), by = k))

sys_mean <- mean(sys_samp[[response_var]], na.rm = TRUE)
sys_sd   <- sd(sys_samp[[response_var]], na.rm = TRUE)

tibble(
  strategy = c("Population", "Systematic"),
  mean = c(pop_mean, sys_mean),
  sd   = c(pop_sd,   sys_sd),
  n    = c(nrow(df), nrow(sys_samp))
)
```

**Prompt (3–4 sentences):** Did systematic sampling approximate the population mean/SD better or worse than SRS?  
What cycle (daily or seasonal) might be interacting with your chosen `k`?

> *Write your answer here.*

---

## Exercise 2 — Cluster sampling (sample days, take all points within those days)

**Definition:** choose a set of clusters (here, **days**) at random, then include **all observations** in the chosen clusters.

This mimics EAES logistics: you may only be able to sample on certain days.

```{r cluster_sampling_days, echo=TRUE, eval=FALSE}
# GOAL: Sample whole days as clusters, then estimate mean/sd.
# TODO: choose number of days to sample.
set.seed(480)

n_days <- ___

days <- df %>%
  distinct(date) %>%
  drop_na(date) %>%
  pull(date)

chosen_days <- sample(days, size = n_days, replace = FALSE)

cluster_samp <- df %>%
  filter(date %in% chosen_days) %>%
  filter(!is.na(.data[[response_var]]))

clust_mean <- mean(cluster_samp[[response_var]], na.rm = TRUE)
clust_sd   <- sd(cluster_samp[[response_var]], na.rm = TRUE)

tibble(
  strategy = c("Population", "Cluster (days)"),
  mean = c(pop_mean, clust_mean),
  sd   = c(pop_sd,   clust_sd),
  n    = c(nrow(df), nrow(cluster_samp))
)
```

**Prompt (3–4 sentences):** Why might cluster sampling have **higher variance** than SRS for the same number of measurements?  
What feature of time series data (hint: autocorrelation) is relevant here?

> *Write your answer here.*

---

## Exercise 3 — Quasi-continuous sampling (fixed schedule time series)

**Definition:** sample regularly over time to create a *subsampled time series*.

This mimics continuous instrumentation that logs at a lower frequency (e.g., hourly instead of 30-min).

```{r quasi_continuous, echo=TRUE, eval=FALSE}
# GOAL: Create a regular subsampled time series.
# TODO: choose a step size (every 2 records = hourly; every 4 = 2-hourly).
step <- ___

qc_samp <- df %>%
  filter(!is.na(.data[[response_var]])) %>%
  slice(seq(1, n(), by = step))

qc_mean <- mean(qc_samp[[response_var]], na.rm = TRUE)
qc_sd   <- sd(qc_samp[[response_var]], na.rm = TRUE)

tibble(
  strategy = c("Population", "Quasi-continuous"),
  mean = c(pop_mean, qc_mean),
  sd   = c(pop_sd,   qc_sd),
  n    = c(nrow(df), nrow(qc_samp))
)
```

### Visual check: does the subsampled series preserve structure?

```{r qc_plot, echo=TRUE, eval=FALSE}
# TODO: plot BOTH population and qc_samp time series (thin lines) for a short window
# HINT: filter to one month to avoid overplotting.

df %>%
  filter(month == ___) %>%   # e.g., "Jul" if month is labeled
  ggplot(aes(x = date, y = .data[[response_var]])) +
  geom_line(alpha = 0.25) +
  theme_classic(base_size = 18) +
  labs(title = "Population time series (subset)", x = NULL, y = response_var)

qc_samp %>%
  filter(month == ___) %>%
  ggplot(aes(x = date, y = .data[[response_var]])) +
  geom_line(alpha = 0.6) +
  theme_classic(base_size = 18) +
  labs(title = "Quasi-continuous sample time series (subset)", x = NULL, y = response_var)
```

**Prompt (3–4 sentences):** Does quasi-continuous sampling preserve the **seasonal** pattern? The **daily** pattern?  
In an EAES context, when is quasi-continuous sampling preferable to sparse discrete sampling?

> *Write your answer here.*

---

## Exercise 4 — Compare all strategies in one table (and interpret)

```{r compare_all, echo=TRUE, eval=FALSE}
# GOAL: Assemble a comparison table of mean/sd error for each strategy.
# NOTE: This assumes you created objects: samp, samp_strat, sys_samp, cluster_samp, qc_samp.
# If your object names differ, update them here.

summ_stats <- function(dat, label) {
  tibble(
    strategy = label,
    n = nrow(dat),
    mean = mean(dat[[response_var]], na.rm = TRUE),
    sd   = sd(dat[[response_var]], na.rm = TRUE)
  )
}

bind_rows(
  tibble(strategy = "Population", n = nrow(df), mean = pop_mean, sd = pop_sd),
  summ_stats(samp, "SRS"),
  summ_stats(samp_strat, "Stratified (month)"),
  summ_stats(sys_samp, "Systematic"),
  summ_stats(cluster_samp, "Cluster (days)"),
  summ_stats(qc_samp, "Quasi-continuous")
) %>%
  mutate(
    mean_error = mean - pop_mean,
    sd_error   = sd - pop_sd
  )
```

**Prompt (5–6 sentences, graded):** Which strategy gave the best estimate of the population mean? Of the population SD?  
Explain *why* in terms of (i) seasonal/diurnal structure and (ii) dependence/autocorrelation.  
If you were designing a real EAES study with limited field days, what hybrid strategy would you propose (e.g., stratified + clustered)?

> *Write your answer here.*

---

## Blocked designs (preview only — do not implement yet)

A **blocked** design means sampling within blocks (time blocks like months, or spatial blocks like sites), then later treating block as structure in the model (often as a random effect).

You already approximated blocking by stratifying over `month`. Later, we will return to this idea when we fit models that include block structure explicitly.

# Submission + self-check

## Before you knit (Run All)
- [ ] Setup chunk runs without errors
- [ ] Data join happened (df_raw has both canopy + climate columns)
- [ ] All chunks run top-to-bottom
- [ ] No objects created only in the Console
- [ ] Interpretation answers are complete sentences

## After you knit
- [ ] Figures appear in the output
- [ ] Tables render and are readable
- [ ] Your selected x and y are clearly stated in the document

**Save, commit, push to Github.**
